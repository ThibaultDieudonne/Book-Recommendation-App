1 - .

2 - Il s'agit d'un projet pour la startup Mycontent. L'objectif de cette startup est de développer une solution de recommandation d'articles et de livres pour les particuliers.
    Le projet sera sous la forme d'une application mobile. Comme l'entreprise ne dispose pas encore de données utilisateur, les données que l'on va utiliser pour ce projet seront celles de globo.com.
    Il s'agit d'un site brésilien, qui permet de lire des articles en ligne sur des sujets variés comme les actualités, la politique, les sports, ou encore les divertissements.
    Ce site possède un traffic important et a publié un échantillon annonimisé de ses données.
    Dans ce projet, notre objectif est de réaliser un MVP, c'est à dire un Produit Minimum Viable, pour tester des systèmes de recommandations. Dans un second temps il est demandé de penser l'architecture future du projet.
    En particulier, il faudra concevoir une architecture capable de prendre en compte de nouveaux utilisateurs et de nouveaux articles.

3 - Le fichier principal du jeu de données est le fichier articles. C'est un fichier au format CSV.
    Chaque ligne est constituée d'un ID d'article, de l'ID de la catégorie associée, de sa date de création, de l'ID de son auteur et du nombre de mots qu'il contient.
    L'autre partie des données, c'est l'historique des articles consultés par les utilisateurs. Cet historique est stocké dans une série de fichiers CSV, qui est contenue dans un dossier.
    Chaque ligne de ces fichiers contient un ID utilisateur, et l'ID de l'article que cet utilisateur a consulté.
    Ces fichiers contenaient aussi d'autres informations que je n'ai pas conservé pour ce projet. C'était les informations relatives à la session utilisateur notamment, comme par exemple type d'appareil utilisé pour consulter l'article.

4 - Au niveau de la préparation des données, j'ai regroupé dans un seul dataset les informations des différents fichiers que je viens de présenter.
    Initialement, mon dataset est constitué d'un concaténation des fichiers d'historique. J'ai ensuite joint la catégorie des articles depuis le fichier principal du jeu de données.
    La colonne category_click_rate, c'est une variable que j'ai construite moi même. Elle représente la fréquence à laquelle l'utilisateur a cliqué sur un article de la catégorie associée à l'article.
    En d'autre termes, on peut considérer cette valeur comme l'intérêt que porte un utilisateur à une catégorie.

5 - L'architecture de mon MVP est assez simple. Elle est constituée d'une application mobile, et d'une API pour obtenir les recommandations.
    L'application mobile permet de sélectionner un utilisateur, et d'afficher les recommendations renvoyées par l'API. Cette application minimale a été développée en amont, elle était donc fournie avec le projet.
    Pour l'instant on ne travaille qu'avec les IDs des articles, puisque de toute manière on a seulement accès aux metadonnées des articles du jeu de globo.com.
    Mon architecture sera déployée dans le cloud en serverless, grâce à Azure Functions. C'est un service qui permet de déployer du code directement en production et de gérer facilement des évènements, comme par exemple nos requêtes.
    En l'occurence, j'utilise des requêtes http, qui sont parfaitement adaptée aux échanges d'ID qu'on souhaite réaliser dans ce projet.

6 - Les modèles pour réaliser des recommandations sont divisés en deux catégories: le collaborative filtering et le content-based filtering.
    Le collaborative filtering consiste à considérer les similarités entre les utilisateurs. L'idée est donc de regrouper les utilisateurs de sorte à maximiser le nombre d'articles en commun qu'ils ont consulté.
    En pratique, ça revient à établir des profils d'utilisateurs. Les articles recommandés sont donc les articles consultés par des utilisateurs similaires.
    Pour établir les similarités entre utilisateurs, on peut par exemple utiliser des algorithmes de clustering.
    Le content based filtering consiste à considérer directement les similarités entre les articles. L'idée est donc de recommander des articles similaires à ceux que l'utilisateur a déjà consulté.
    Une différence majeure avec le collaborative filtering est qu'on ne peut pas construire les similarités entre article directement par clustering, il faut disposer d'un moyen de comparer les articles.
    En pratique, on dévelopera donc un coefficient de similarité.

7 - Le premier modèle que j'ai testé est SVD, pour singular value decomposition. C'est un modèle qui a été popularisé lors d'un concours organisé par netflix en 2009.
    L'ojectif du concours était de présenter des algorithmes de collaborative filtering pour prédire la note qu'un utilisateur accorderait à un film en se basant uniquement sur les notes déjà attribuées par l'ensemble des utilisateurs.
    SVD est un algorithme de factorisation de matrice. Son principe est de représenter les notes attribuées par chaque utilisateur à chaque film dans une matrice éparse.
    On considère ensuite cette matrice comme le produit de deux vecteurs, un vecteurs d'utilisateurs et l'autre d'articles.
    L'idée est donc de choisir la paire de vecteurs qui reconstruit une matrice dont les valeurs sont au plus proches de celles de la matrice de base.
    J'ai utilisé l'implémentation faite dans la librairie suprise, qui contient des modèles de recommandations.

8 - Le deuxième modèle que j'ai implémenté est un KNN, pour K nearest neighbours. Il s'agit d'un algorithme de clustering qui regroupe des individus semblables.
    KNN fonctionne en minimisant la distance entre les individus appartenant à un même cluster.
    Il faut donc utiliser une métrique adaptée. En l'occurence, on utilise la similarité cosinus, sur les paires de vecteurs construits à partir des articles déjà consultés par deux utilisateurs.
    La similarité cosinus est définie comme le produit scalaire de deux vecteurs sur le produit de leur norme, ce qui permet en pratique de quantifier leur semblabilité.
    Les articles recommandés seront les articles les plus consultés par des utilisateurs similaires.

9 - J’ai implémenté mon propre algorithme de recommandations. Il consiste à construire une table de similarité entre les articles.
    Cette table est construite en utilisant la similarité cosinus sur la représentation vectorielle des articles. Cette représentation vectorielle s'appelle embedding. Dans notre projet, l'embedding est fourni avec les données.
    Il a été construit grâce aux similarités du vocabulaire employé dans les articles. Comme on ne dispose pas des articles, je n'ai pas pu tenter de le reconstruire dans ce projet.
    Pour chaque article qui n’a pas encore été lu par l’utilisateur, on fait la moyenne des coefficients de similarité avec chaque article déjà lu.
    Les articles recommandés sont simplement ceux qui possèdent le plus haut score moyen.

10 - Dans le projet il était demandé de tester les modèles et l'API. J'ai donc réalisé une série de tests unitaire, qui vérifient pour chaque modèle que le format des prédictions est bien respecté.
     Ces tests vérifient également que les ID d'articles recommandés sont bien des ID existants.

11 - Pour évaluer les modèles, il n’existe pas de meilleure métrique, car on ne peut pas caractériser uniformément les goût humains.
     D'un point de vue de l'expérience utilisateur il n'est pas toujours pertinent de recommander les articles les plus semblables possibles, notamment pour des raisons de redondance d'information ou d'absence de diversification.
     Pour tout de même avoir une métrique pour comparer les modèles, j'ai choisi d’utiliser une des seules informations disponibles sur les articles: leur catégorie.
     Le score est la fréquence d’articles suggérés dont la catégorie a déjà été consultée par l’utilisateur.
     En pratique, cela donne une indication de la diversité des thèmes des articles suggérés, c'est à dire "dans quel mesure on recommande des articles dont les thèmes ont déjà été consultés par l'utilisateur".
     On peut voir que les articles recommandés par mon modèle content based utilisant l'embedding appartiennent plus souvent à une catégorie déjà consultée par l'utilisateur.
     Une interprétation possible est que les modèles de collaborative filtering trouvent des intérêts communs potentiels, là ou mon algorithme content based est limité aux similarités entre articles.

12 - J'ai créé l'architecture du futur système capable de prendre en compte de nouveaux articles et de nouveaux utilisateurs. Pour une mise en production scalable j'ai choisi un certain nombre de services Azure à mettre en place.
     [Décrire] 
     
13 - En conclusion, je dirai que je n'ai pas rencontré de difficulté particulière dans ce projet. Les outils Azure sont particulièrement bien documentés et m'ont permi de déployer mes modèles très facilement.
     J'ai tout de même un regret par rapport au jeu de données, notamment le fait qu'il soit constitué simplement de l'historique de consultation des articles et pas de notes attribuées par les utilisateurs.
     Ca m'aurait permis d'explorer des modèles de recommandations plus complexes, en particulier certain modèles hybrides, entre collaborative filtering et content based filtering.

14 - DEMO
    